---
title: "Unidad 5 — Agrupando Observaciones"
subtitle: "Semana 09: Clustering"
author: "Eduard F. Martínez González"
---
  
<a href="mailto:efmartinez@icesi.edu.co" style="color:black;">
<img src="pic/correo.png" alt="Email" width="20" height="20"/> efmartinez@icesi.edu.co
</a>

<a href="https://github.com/eduard-martinez" style="color:black;"> <img src="pic/github.png" alt="Qries" width="20" height="20"/> eduard-martinez</a>

<a href="https://twitter.com/emartigo" style="color:black;"> <img src="pic/twitter.jpg" alt="Qries" width="20" height="20"/> @emartigo</a>

<a href="https://eduard-martinez.github.io" style="color:black;"> <img src="pic/link.png" alt="Qries" width="20" height="20"/> https://eduard-martinez.github.io</a>

---

# Aplicación en R

Para ejemplificar el uso de K-means se trabajará con una base de notas del curso, que reúne para cada estudiante sus calificaciones en talleres, quices, parcial y midterm. Imagine un diagrama de dispersión donde en el eje X se ubica el promedio de talleres y en el eje Y el promedio de quices. Al ajustar K-means con k = 3, el algoritmo puede revelar patrones como los siguientes: Cluster 1, formado por estudiantes con desempeños altos y consistentes en trabajos y evaluaciones cortas; Cluster 2, con estudiantes que rinden mejor en actividades prácticas (talleres) pero muestran rezagos en quices; y Cluster 3, que agrupa desempeños más bajos o inestables en ambas dimensiones.

Este ejercicio permite observar cómo el algoritmo construye segmentos naturales a partir de los datos, sin categorías predefinidas, resaltando la utilidad del aprendizaje no supervisado para explorar perfiles y patrones de desempeño académico.

::: callout-tip
**Cómo usar este material:** Puedes ejecutar los _chunks_ de R directamente en el navegador gracias a **webR** (según tu `_quarto.yml`), sin instalar nada localmente.
:::

## Preparación del entorno

El propósito de este bloque es asegurar un entorno limpio y reproducible. Primero, eliminamos objetos previos que puedan interferir con el análisis. Después, cargamos los paquetes necesarios para manipulación de datos, visualización, generación de resúmenes y ejecución de `K-means`. Con esto, dejamos el entorno preparado para comenzar.

```{webr-r}
## Author:
## Date: 

## limpiar entorno
rm(list = ls())

## cargar paquetes
require(dplyr)      # Manipulación de datos 
require(ggplot2)    # Visualización de datos
require(skimr)      # Resúmenes rápidos y completos

## print
print("Listo!")
```

## Ingesta de datos (carga desde archivo o URL)

En esta sección se realiza la ingesta de datos, es decir, la carga de la base de notas del curso que usaremos para los ejercicios de clustering. El dataset llamado `grades` incluye, para cada estudiante, su código y las calificaciones en `talleres`, `quices`, `parcial` y `midterm` (escala 0–5). Estos atributos permitirán aplicar `K-means` para identificar patrones de desempeño y segmentar a los estudiantes en grupos con perfiles similares.

Para garantizar reproducibilidad, podemos trabajar de dos maneras:  

1. **Archivo local**: leer directamente el archivo `data.csv` que acompaña a este material.  
2. **Fuente externa (opcional)**: usar una URL (por ejemplo, un repositorio en GitHub) para que cualquier estudiante pueda replicar el ejercicio sin necesidad del archivo local.

Una vez cargados los datos, listamos los objetos en memoria para confirmar que el dataset esperado (`grades`) está disponible y listo para la exploración inicial.

```{webr-r}
#| warning: false
#| message: false

## generar los datos
source("https://raw.githubusercontent.com/ba-in-r/01-slides/main/week-09/data/grades.r")

## chuequear objetos en la memoria
ls()

## atributos de grades
class(grades)
skim(grades)
```

## Selección de variables

En este paso se eligen únicamente las variables numéricas relevantes para el agrupamiento. En el caso de las notas, pueden incluirse `taller`, `quiz`, `parcial` y `midterm.` Estas variables son adecuadas para `K-means` porque están en la misma escala (0–5) y describen cuantitativamente el desempeño académico.

Para un ejemplo simple, trabajaremos con dos dimensiones (`quiz` y `parcial`) a fin de visualizar con claridad la lógica del clustering. Al reducir la base a este subconjunto se garantiza que el análisis se centre en atributos comparables y se excluyan identificadores u otras columnas que no aportan a la formación de grupos.

```{webr-r}
## filtrar variables
db <- select(.data=grades , quiz,  parcial)

## print
print("Listo!")
```

## Escalado

Antes de aplicar `K-means` es buena práctica escalar las variables para que todas queden con media 0 y desviación estándar 1. Así se evita que alguna dimensión pese más en el cálculo de distancias euclidianas. Aunque aquí todas las notas comparten el rango 0–5, el escalado ayuda a estandarizar y comparar contribuciones.

Con `scale()` se obtiene una matriz estandarizada lista para el análisis. Luego, se usa `skim()` para comprobar rápidamente que la transformación se aplicó correctamente (medias cercanas a 0 y desviaciones cercanas a 1).

```{webr-r}
## escalar
db <- scale(db)

## check data (skim)
skim(db)

## visualicemos las variables
ggplot(data=db , aes(x=quiz , y=parcial)) +
geom_point() +
theme_minimal()
```

## Ajuste de K-means con K = 4

En este bloque se entrena el modelo `K-means` fijando el número de grupos en `k = 4`. Primero, se establece una semilla (`set.seed(2024)`) para asegurar reproducibilidad, dado que `K-means` depende de inicializaciones aleatorias de los centroides.

Luego, con `kmeans()` se ajusta el modelo sobre la matriz estandarizada (`db` creada en el paso anterior), indicando `centers = 4`. El argumento `nstart = 30` hace que el algoritmo arranque desde 30 inicializaciones distintas y escoja la mejor solución (menor SSE), reduciendo el riesgo de mínimos locales.

El objeto resultante `km` contiene la información clave del modelo: asignación de observaciones a clusters, coordenadas de los centroides y medidas de ajuste (suma de cuadrados intra/inter).

```{webr-r}
## fijar semilla
set.seed(2024)

## ajustar modelo
km <- kmeans(db, centers = 4, nstart = 30)

## print
print("Listo!")
```

A continuación se construye un objeto con la asignación individual agregando la columna `cluster` al objeto original de `grades`. Se convierte en factor para facilitar la interpretación y el uso en `gráficos/tablas`.

```{webr-r}
## Agregar variable de cluster
grades_c <- grades %>% 
            mutate(cluster = factor(km$cluster))

## head(spotify_c)
head(grades_c)
```

## Inspeccionar los clusters

Un primer vistazo útil es (i) el tamaño de cada cluster y (ii) un dispersograma de parcial vs. quiz coloreado por cluster.

```{webr-r}
## plot
ggplot(grades_c , aes(x=parcial , y=midterm , color=cluster)) +
geom_point(alpha = 0.6) +
theme_minimal(base_size = 12)
```


