---
title: "Unidad 9 ‚Äî Clasificaci√≥n"
subtitle: "Semana 14: Modelo kNN (k-Near Neighbors)"
author: "Eduard F. Mart√≠nez Gonz√°lez"
---

<a href="mailto:efmartinez@icesi.edu.co" style="color:black;">
<img src="pic/correo.png" alt="Email" width="20" height="20"/> efmartinez@icesi.edu.co
</a>

<a href="https://github.com/eduard-martinez" style="color:black;"> <img src="pic/github.png" alt="Qries" width="20" height="20"/> eduard-martinez</a>

<a href="https://twitter.com/emartigo" style="color:black;"> <img src="pic/twitter.jpg" alt="Qries" width="20" height="20"/> @emartigo</a>

<a href="https://eduard-martinez.github.io" style="color:black;"> <img src="pic/link.png" alt="Qries" width="20" height="20"/> https://eduard-martinez.github.io</a>

# Recordemos la clase anterior

En la sesi√≥n pasada introdujimos los **modelos de clasificaci√≥n param√©tricos**, usando como ejemplo la **Regresi√≥n Log√≠stica (Logit)**. All√≠ aprendimos que:

- El objetivo era **predecir una variable categ√≥rica**, como *acepta/no acepta* o *mora/no mora*.  
- La regresi√≥n log√≠stica estimaba una **probabilidad** $P(Y = 1 | X)$ a partir de una **relaci√≥n funcional espec√≠fica** entre las variables.  
- La interpretaci√≥n se centraba en los **coeficientes** y los **odds ratios**, √∫tiles para explicar el efecto de cada variable.

Sin embargo, este enfoque tiene limitaciones:
- Supone una **forma funcional fija** (sigmoide).  
- Puede perder precisi√≥n si la relaci√≥n entre variables es **no lineal o compleja**.  

**Motivaci√≥n de la clase de hoy:** Modelos como la **regresi√≥n log√≠stica** suponen una relaci√≥n funcional espec√≠fica entre las variables $X$ y la probabilidad de pertenecer a una clase $P(Y=1)$. Sin embargo, en muchos casos esta relaci√≥n puede ser **no lineal o desconocida**, y el modelo puede perder capacidad predictiva.

## El modelo k-Nearest Neighbors (kNN)

El algoritmo kNN clasifica una observaci√≥n **seg√∫n las clases de sus vecinos m√°s cercanos** en el espacio de caracter√≠sticas.

1. Calcula la **distancia** entre la observaci√≥n nueva y todas las observaciones del conjunto de entrenamiento.  
2. Selecciona los **k vecinos m√°s cercanos** (por ejemplo, los 5 m√°s pr√≥ximos).  
3. Asigna la observaci√≥n a la **clase mayoritaria** entre esos vecinos.

![](figures/knn.gif)
**Intuici√≥n pr√°ctica:** La idea central es que observaciones similares tienden a tener comportamientos similares. Si la mayor√≠a de los estudiantes con caracter√≠sticas parecidas a un nuevo estudiante se retiraron del curso, el modelo predecir√° que probablemente ese estudiante tambi√©n se retire. Por ejemplo, si un estudiante asiste poco, estudia pocas horas y entrega pocos trabajos, y entre sus 7 vecinos m√°s parecidos el *80%* se retir√≥, el modelo clasificar√° al nuevo estudiante como *retirado*.

### Elecci√≥n del par√°metro *k*

El valor de **k** determina cu√°ntos vecinos se toman en cuenta para clasificar una nueva observaci√≥n. Este par√°metro controla el equilibrio entre *precisi√≥n local* y *estabilidad general* del modelo.

| Valor de k | Caracter√≠sticas | Riesgo |
|-------------|----------------|--------|
| **Peque√±o (k = 1‚Äì3)** | Modelo muy sensible al ruido (alta varianza). | Sobreajuste (*overfitting*). |
| **Grande (k = 20‚Äì50)** | Promedia muchos vecinos, suaviza la frontera. | Subajuste (*underfitting*). |

En la pr√°ctica, si $k$ es muy peque√±o, el modelo puede reaccionar exageradamente a casos at√≠picos. Si $k$ es demasiado grande, la predicci√≥n se vuelve gen√©rica, mezclando grupos distintos. En un contexto de *Business Analytics*, elegir un *k* adecuado equivale a decidir **cu√°nto contexto** se usa para tomar decisiones:

 - Un *k* peque√±o = decisiones altamente personalizadas (pero m√°s arriesgadas).  
 - Un *k* grande = decisiones m√°s estables, pero menos sensibles a diferencias individuales.

**¬øC√≥mo elegir el mejor k?:** En la pr√°ctica, se prueban varios valores de *k* y para cada valor, se calcula el error de clasificaci√≥n (porcentaje de predicciones incorrectas). Finalmente se elige el *k* que minimiza el error en los datos de validaci√≥n.

### Medidas de distancia

El algoritmo depende de c√≥mo se define la ‚Äúcercan√≠a‚Äù entre observaciones. Las distancias m√°s comunes son:

| Distancia | F√≥rmula | Uso t√≠pico |
|------------|----------|------------|
| **Euclidiana** | \( d(x,y)=\sqrt{\sum_i (x_i-y_i)^2} \) | Variables num√©ricas continuas |
| **Manhattan** | \( d(x,y)=\sum_i |x_i-y_i| \) | Datos con escalas heterog√©neas |
| **Minkowski / Coseno** | Generalizaciones √∫tiles en texto o redes | Casos avanzados |

Es fundamental **escalar las variables** antes de aplicar kNN para evitar que las variables con valores grandes dominen la distancia.

## Evaluaci√≥n del modelo

Las m√©tricas de evaluaci√≥n son las mismas utilizadas en otros modelos de clasificaci√≥n, como la regresi√≥n log√≠stica. Sin embargo, en el caso del **kNN**, estas m√©tricas permiten analizar qu√© tan bien el modelo est√° reconociendo patrones en funci√≥n de la *similitud entre observaciones*.

| M√©trica | Descripci√≥n | Interpretaci√≥n pr√°ctica |
|----------|--------------|-------------------------|
| **Exactitud (Accuracy)** | Proporci√≥n de clasificaciones correctas sobre el total. | Eval√∫a el desempe√±o global del modelo. √ötil cuando las clases est√°n balanceadas. |
| **Sensibilidad (Recall)** | Capacidad del modelo para identificar correctamente los **casos positivos**. | Mide cu√°ntos clientes en riesgo (*mora = s√≠*) fueron detectados correctamente. |
| **Especificidad** | Capacidad del modelo para identificar correctamente los **casos negativos**. | Eval√∫a qu√© tan bien clasifica los clientes ‚Äúbuenos pagadores‚Äù. |
| **Precisi√≥n (Precision)** | Proporci√≥n de verdaderos positivos entre los predichos como positivos. | Indica qu√© tan confiables son las alertas del modelo (por ejemplo, clientes en mora realmente en mora). |
| **F1-Score** | Media arm√≥nica entre precisi√≥n y sensibilidad. | Equilibrio entre detectar y no generar falsas alarmas. |
| **AUC-ROC** | √Årea bajo la curva ROC; mide el poder discriminatorio del modelo. | Cuanto m√°s se acerque a 1, mejor separa las clases. |

::: callout-note
**Matriz de confusi√≥n:** Resume los aciertos y errores del modelo de clasificaci√≥n. Permite calcular todas las m√©tricas anteriores y visualizar c√≥mo se distribuyen las predicciones.

|                | **Predicho: S√≠** | **Predicho: No** |
|----------------|------------------|------------------|
| **Real: S√≠**   | Verdadero Positivo (TP) | Falso Negativo (FN) |
| **Real: No**   | Falso Positivo (FP) | Verdadero Negativo (TN) |
:::

# Aplicaci√≥n en R

Para ilustrar el uso de los **modelos de clasificaci√≥n no param√©tricos**, trabajaremos con una base sint√©tica que representa a **estudiantes inscritos en un curso universitario**. Cada registro contiene informaci√≥n sobre el comportamiento acad√©mico y el desempe√±o del estudiante a lo largo del semestre, lo que nos permitir√° **predecir si un estudiante aprobar√° o no el curso** utilizando el modelo **k-Nearest Neighbors (kNN)**.

En este contexto:

- Cada **observaci√≥n** corresponde a un estudiante.  
- La **variable dependiente** es categ√≥rica (`aprueba`: *S√≠* / *No*).  
- Las **variables explicativas** describen aspectos como las horas de estudio, asistencia, participaci√≥n, uso de R, trabajos entregados y afinidad con la estad√≠stica.  

El objetivo de este ejercicio es aplicar el algoritmo kNN para responder preguntas como:

- ¬øPodemos predecir si un estudiante aprobar√° el curso a partir de su perfil acad√©mico?  
- ¬øQu√© tan precisa es la clasificaci√≥n seg√∫n el n√∫mero de vecinos (*k*) considerados?  
- ¬øC√≥mo cambia la calidad de las predicciones al variar *k* o al escalar las variables?

::: callout-tip
üí° **C√≥mo usar este material:**  
Puedes ejecutar los _chunks_ de R directamente en el navegador gracias a **webR**, sin necesidad de instalar nada localmente.
:::

## Preparaci√≥n del entorno

El prop√≥sito de este bloque es asegurar un entorno limpio, reproducible y funcional antes de iniciar el an√°lisis.  
Primero, eliminamos cualquier objeto previo que pueda interferir con la sesi√≥n actual. Luego, instalamos (si es necesario) y cargamos los paquetes requeridos para la manipulaci√≥n de datos, la implementaci√≥n del algoritmo k-Nearest Neighbors (kNN), la evaluaci√≥n del modelo y la visualizaci√≥n de resultados. Con esto, dejamos el entorno preparado para comenzar el an√°lisis aplicado de clasificaci√≥n no param√©trica.

```{webr-r}
## Limpiar el entorno de trabajo
rm(list = ls())

## Instalar paquetes (solo si es necesario)
install.packages("tidyverse")
install.packages("class")
install.packages("caret")
install.packages("pROC")

## Cargar librer√≠as
library(tidyverse)  # Manipulaci√≥n y visualizaci√≥n de datos
library(class)      # Implementaci√≥n del algoritmo kNN
library(caret)      # M√©tricas y matriz de confusi√≥n
library(pROC)       # Calcular la curva ROC y el AUC
 
## Fijar semilla para reproducibilidad
set.seed(123)
```

::: callout-note
`tidyverse`: facilita la transformaci√≥n, manipulaci√≥n y visualizaci√≥n de datos.
`class`: contiene la funci√≥n `knn()` que implementa el algoritmo k-Nearest Neighbors.
`caret`: permite calcular m√©tricas de desempe√±o, generar matrices de confusi√≥n y realizar validaciones cruzadas.
`pROC`: se emplea para evaluar el poder discriminatorio del modelo mediante la curva ROC y el √°rea bajo la curva (AUC).
:::

## Ingesta de datos 

En esta secci√≥n realizamos la ingesta de datos, es decir, el proceso de generar o cargar la base que utilizaremos para estimar el modelo KNN. Cada registro representa a un estudiante, con variables relacionadas con su esfuerzo, participaci√≥n y rendimiento a lo largo del semestre.

La estructura de los datos es la siguiente:

	‚Ä¢	horas_estudio: promedio semanal de horas dedicadas al curso.
	‚Ä¢	asistencia: porcentaje de asistencia a clase.
	‚Ä¢	participacion: nivel de participaci√≥n en clase (0‚Äì100).
	‚Ä¢	uso_de_R: nivel de dominio de R (1‚Äì5).
	‚Ä¢	trabajos_entregados: cantidad de trabajos entregados (0‚Äì5).
	‚Ä¢	afinidad_estadistica: gusto por la estad√≠stica (0‚Äì100).
	‚Ä¢	aprueba: resultado final (1 = aprueba, 0 = reprueba).
	‚Ä¢	retira: indica si el estudiante se retir√≥ del curso antes de finalizar (1 = s√≠, 0 = no).

Nuestro objetivo ser√° estimar c√≥mo cada una de estas variables influye en la probabilidad de aprobar el curso.

```{webr-r}
#| warning: false
#| message: false

## generar los datos
source("https://raw.githubusercontent.com/ba-in-r/01-slides/main/week-13/data/week-13.r")

## chuequear objeto
names(datos)
head(datos)
```

## Preparaci√≥n de los Datos

Antes de aplicar el modelo **k-Nearest Neighbors (kNN)**, es fundamental preparar adecuadamente los datos. 

### Escalar Variables 

A diferencia de la regresi√≥n log√≠stica, donde las variables se utilizan directamente dentro de una funci√≥n matem√°tica, el kNN **se basa en distancias entre observaciones**. Por esta raz√≥n, las variables deben estar en una **misma escala** para que ninguna domine el c√°lculo de distancia. Por ejemplo, si una variable se mide en porcentajes (0‚Äì100) y otra en horas (0‚Äì10), la de mayor rango influir√° desproporcionadamente en la predicci√≥n. Para evitarlo, aplicamos un proceso de **escalamiento y centrado**, que transforma todas las variables num√©ricas de manera que tengan **media 0 y desviaci√≥n est√°ndar 1**. A continuaci√≥n seleccionamos las variables num√©ricas relevantes. Posteriormente aplicamos el escalamiento con `scale()` y finalmente volvemos a unir la variable objetivo (`aprueba`) para mantener la estructura original de la base.

```{webr-r}
## Seleccionamos solo las variables num√©ricas
vars <- select(datos, horas_estudio:afinidad_estadistica)

## Escalamos (centrar y escalar)
datos_scaled <- as.data.frame(scale(vars))

## Combinamos nuevamente con la variable objetivo
datos_scaled$aprueba <- datos$aprueba

## check datos
head(datos_scaled)
```

::: callout-note
**Importancia del escalamiento:** El kNN calcula distancias entre observaciones (por defecto, euclidianas).
Si las variables no se escalan, las que tienen rangos mayores (por ejemplo, asistencia = 0‚Äì100) dominar√°n el c√°lculo, distorsionando la noci√≥n de ‚Äúvecindad‚Äù. El escalamiento garantiza que todas las variables contribuyan de manera equilibrada al proceso de clasificaci√≥n.
:::

### Divisi√≥n en entrenamiento y prueba

Antes de entrenar el modelo, dividimos la base de datos en dos subconjuntos: uno para **entrenamiento** y otro para **prueba**. Esta separaci√≥n es fundamental en el aprendizaje supervisado, ya que permite **evaluar la capacidad de generalizaci√≥n del modelo** ‚Äîes decir, qu√© tan bien predice sobre casos nuevos que no ha ‚Äúvisto‚Äù durante el entrenamiento.

- El conjunto de **entrenamiento** se usa para ajustar el modelo (70% de las observaciones).  
- El conjunto de **prueba** se utiliza para evaluar su desempe√±o (30% restante).

Esta pr√°ctica evita el **sobreajuste (overfitting)**, que ocurre cuando el modelo aprende demasiado bien los datos de entrenamiento, pero falla al aplicarse a nuevas observaciones.

```{webr-r}
## separar datos
set.seed(123)
train_idx <- sample(1:nrow(datos_scaled), 0.7*nrow(datos_scaled))

## datos de entrenamiento
train_x <- datos_scaled[train_idx, 1:6]

## datos de prueba
test_x  <- datos_scaled[-train_idx, 1:6]

## variables de resultado
train_y <- datos_scaled$aprueba[train_idx]
test_y  <- datos_scaled$aprueba[-train_idx]

## inspect data
head(train_x)
```

## Entrenamiento del Modelo kNN

En este paso aplicamos el algoritmo **k-Nearest Neighbors (kNN)** utilizando los conjuntos de entrenamiento (`train_x`, `train_y`) y de prueba (`test_x`).  El modelo se entrena con los datos conocidos (estudiantes cuyo resultado ya sabemos) y luego **clasifica los nuevos casos** seg√∫n sus *vecinos m√°s cercanos*.

El par√°metro **k = 5** indica que para cada observaci√≥n en el conjunto de prueba, el algoritmo buscar√° los **5 estudiantes m√°s similares** (en t√©rminos de distancia) dentro del conjunto de entrenamiento. Luego asignar√° la clase mayoritaria (*S√≠* o *No*) entre esos vecinos.

```{webr-r}
## Ajustamos con k = 5 vecinos
pred_knn <- knn(train=train_x , test=test_x , cl=train_y , k=5)

## Visualizamos las primeras predicciones
resultados <- data.frame(Real=test_y , Predicho=pred_knn)
head(resultados , 20)
```

## Matriz de confusi√≥n

La matriz de confusi√≥n compara las predicciones del modelo con los valores reales y permite visualizar los aciertos y errores de clasificaci√≥n.

```{webr-r}
## obtener matrix
conf_matrix <- table(Predicho = pred_knn, Real = test_y)
conf_matrix
```

Interpretaci√≥n de los resultados:

	‚Ä¢	Verdaderos positivos (VP): el modelo predice aprobar y el estudiante aprueba.
	‚Ä¢	Verdaderos negativos (VN): el modelo predice reprobar y el estudiante reprueba.
	‚Ä¢	Falsos positivos (FP): el modelo predice aprobar pero el estudiante reprueba.
	‚Ä¢	Falsos negativos (FN): el modelo predice reprobar pero el estudiante aprueba.

## Curva ROC y AUC

La curva ROC muestra la relaci√≥n entre la tasa de verdaderos positivos (sensibilidad) y la tasa de falsos positivos (1 - especificidad) para distintos umbrales de decisi√≥n.

El √Årea Bajo la Curva (AUC) mide el desempe√±o general del modelo:

	‚Ä¢	AUC = 0.5 ‚Üí el modelo no discrimina (como lanzar una moneda).
	‚Ä¢	AUC = 1 ‚Üí el modelo clasifica perfectamente.

```{webr-r}
## Calcular la curva ROC y el AUC
roc_obj <- roc(test_y , as.numeric(pred_knn))

## Mostrar AUC
auc(roc_obj)

## Graficar la curva ROC
plot(roc_obj, col = "blue", lwd = 2, main = "Curva ROC ‚Äî Modelo Logit")
abline(a = 0, b = 1, lty = 2, col = "gray")
```

::: callout-note
Un valor de AUC entre 0.7 y 0.9 indica un buen poder discriminatorio, mientras que valores superiores a 0.9 suelen considerarse excelentes. Si el AUC est√° cerca de 0.5, el modelo no est√° capturando patrones √∫tiles.
:::

## Evaluaci√≥n con distintos valores de k

El par√°metro **k** es el elemento central del algoritmo *k-Nearest Neighbors*, ya que determina **cu√°ntos vecinos** se consideran al clasificar una nueva observaci√≥n. Valores de *k* peque√±os hacen que el modelo sea **m√°s sensible al ruido** (puede sobreajustarse), mientras que valores grandes lo vuelven **m√°s general** (puede subajustarse).

En esta secci√≥n exploramos c√≥mo cambia la **precisi√≥n del modelo (accuracy)** al variar el n√∫mero de vecinos considerados.  
Para ello, probamos distintos valores impares de *k* ‚Äîentre 1 y 21‚Äî y calculamos el porcentaje de clasificaciones correctas para cada uno.

```{webr-r}
ks <- seq(1, 21, 2)  # valores impares de k
accuracy <- map_dbl(ks, function(k) {
                    pred <- knn(train = train_x, test = test_x, cl = train_y, k = k)
                    mean(pred == test_y)
                  })

# Tabla resumen
tibble(k=ks , accuracy=accuracy)
```

El siguiente gr√°fico muestra c√≥mo var√≠a la exactitud del modelo conforme aumenta el n√∫mero de vecinos k. Este tipo de an√°lisis es √∫til para identificar el valor de k que ofrece un equilibrio entre precisi√≥n y estabilidad.

```{webr-r}
# Gr√°fico de precisi√≥n seg√∫n k
tibble(k = ks, accuracy = accuracy) %>%
ggplot(aes(x = k, y = accuracy)) +
geom_line(color = "steelblue") +
geom_point(size = 2) +
labs(title = "Precisi√≥n del modelo seg√∫n n√∫mero de vecinos (k)",
     x = "N√∫mero de vecinos (k)", y = "Exactitud (Accuracy)") +
theme_minimal()
```

# Actividad en Clase

## Instrucciones:

1. Ejecute los *chunks* de c√≥digo proporcionados en R (puede hacerlo directamente en el navegador o en RStudio).  
2. Observe los resultados obtenidos en cada secci√≥n.  
3. Genere un documento en **Word (.docx)** donde:  
   - Copie las preguntas que aparecen al final.  
   - Redacte sus interpretaciones y conclusiones con base en los resultados.  
   - **No copie el c√≥digo**, solo redacte sus respuestas.  
4. Suba su documento y su **script en R** a la plataforma **Intu**, en la actividad correspondiente a la **Semana 14 ‚Äî Modelo kNN (Predicci√≥n de Retiro)**.

## Estimaci√≥n del modelo kNN

Ejecute el siguiente c√≥digo para estimar un modelo **k-Nearest Neighbors (kNN)** que prediga la **probabilidad de que un estudiante se retire del curso**, usando las variables explicativas relacionadas con esfuerzo y participaci√≥n.  
‚ö†Ô∏è No incluya la variable `aprueba` en el modelo.

```{webr-r}
## Preparar los datos
vars <- select(datos, horas_estudio:afinidad_estadistica)
datos_scaled <- as.data.frame(scale(vars))
datos_scaled$retira <- factor(datos$retira, levels = c(0, 1), labels = c("No", "S√≠"))

## Modelo kNN con k = 5
pred_knn_5 <- knn(train = datos_scaled[, 1:6],
                  test  = datos_scaled[, 1:6],
                  cl = datos_scaled$retira,
                  k = 5)

## Matriz de confusi√≥n
conf_5 <- table(Predicho = pred_knn_5, Real = datos_scaled$retira)
conf_5
``` 

```{webr-r}
## Calcular exactitud del modelo con k = 5
VP <- conf_5["S√≠", "S√≠"]
VN <- conf_5["No", "No"]
FP <- conf_5["S√≠", "No"]
FN <- conf_5["No", "S√≠"]

## plot accuracy
accuracy_5 <- (VP + VN) / sum(conf_5)
accuracy_5
``` 

```{webr-r}
## Calcule la curva ROC y el AUC
roc_5 <- roc(datos_scaled$retira, as.numeric(pred_knn_5))
auc(roc_5)

plot(roc_5, col = "blue", lwd = 2, main = "Curva ROC ‚Äî k = 5")
```
