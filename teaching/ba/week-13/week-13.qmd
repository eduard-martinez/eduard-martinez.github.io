---
title: "Unidad 9 ‚Äî Clasificaci√≥n"
subtitle: "Semana 13: Modelo Logit"
author: "Eduard F. Mart√≠nez Gonz√°lez"
---

<a href="mailto:efmartinez@icesi.edu.co" style="color:black;">
<img src="pic/correo.png" alt="Email" width="20" height="20"/> efmartinez@icesi.edu.co
</a>

<a href="https://github.com/eduard-martinez" style="color:black;"> <img src="pic/github.png" alt="Qries" width="20" height="20"/> eduard-martinez</a>

<a href="https://twitter.com/emartigo" style="color:black;"> <img src="pic/twitter.jpg" alt="Qries" width="20" height="20"/> @emartigo</a>

<a href="https://eduard-martinez.github.io" style="color:black;"> <img src="pic/link.png" alt="Qries" width="20" height="20"/> https://eduard-martinez.github.io</a>

# ¬øQu√© es un problema de clasificaci√≥n?

![](clasfication-gif.gif)

En *Business Analytics*, los modelos de **clasificaci√≥n** se utilizan cuando la **variable de respuesta es categ√≥rica** (por ejemplo, *acepta/no acepta*, *fraude/no fraude*, *compra/no compra*).  
El objetivo es **asignar observaciones a categor√≠as** con base en sus caracter√≠sticas observadas.

**Ejemplos t√≠picos:**

- Determinar si un cliente pagar√° su cr√©dito o caer√° en mora.  
- Identificar si una transacci√≥n es leg√≠tima o fraudulenta.  
- Predecir si un estudiante aprobar√° o no un curso.  
- Clasificar correos en ‚Äúspam‚Äù o ‚Äúno spam‚Äù.

## Modelaci√≥n

### El Modelo Logit

En el contexto de **Business Analytics**, cuando la variable de inter√©s es dicot√≥mica (por ejemplo, *comprar/no comprar*, *aprobar/reprobar*, *renovar/no renovar*), necesitamos un modelo que relacione las caracter√≠sticas observadas \(X\) con la **probabilidad de √©xito** \(P(Y=1)\). 

El modelo **Logit** propone una relaci√≥n no lineal entre estas variables mediante la **funci√≥n log√≠stica**:

$P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \cdots + \beta_k X_k)}}$

Esta transformaci√≥n convierte una combinaci√≥n lineal de predictores ($\beta_0 + \beta_1 X_1 + \cdots$) en un valor comprendido entre **0 y 1**, es decir, una probabilidad v√°lida.

üìà **Idea clave:**  Mientras que la regresi√≥n lineal puede producir predicciones fuera del rango [0,1], el modelo Logit **comprime la escala** y captura relaciones no lineales entre las variables explicativas y la probabilidad del evento.

### Interpretaci√≥n matem√°tica y emp√≠rica

En lugar de modelar directamente la probabilidad, el modelo Logit transforma la relaci√≥n a trav√©s del **logaritmo de las odds (raz√≥n de probabilidades)**, definido como:

$\log\left(\frac{P(Y=1)}{1 - P(Y=1)}\right) = \beta_0 + \beta_1 X_1 + \cdots + \beta_k X_k$

Esta ecuaci√≥n implica que los **log-odds** cambian linealmente con los valores de \(X\), aunque la probabilidad \(P(Y=1)\) lo haga de manera no lineal. De este modo, el Logit puede modelar relaciones complejas, donde los efectos marginales de cada variable disminuyen a medida que la probabilidad se acerca a 0 o 1.

En la pr√°ctica, este comportamiento **‚Äúen S‚Äù o sigmoide** refleja situaciones reales de decisi√≥n:

- Un aumento en las horas de estudio tiene un fuerte impacto cuando un estudiante est√° indeciso (probabilidad ‚âà 0.5),  
  pero un efecto mucho menor si ya tiene una probabilidad muy alta o muy baja de aprobar.

### Odds y log-odds: intuici√≥n pr√°ctica

**Odds (raz√≥n de probabilidades):** $\text{odds} = \frac{P(Y=1)}{1 - P(Y=1)}$ 

Ejemplo: si $P=0.8$, las odds son 4 a 1 (es decir, cuatro veces m√°s probable que ocurra el evento que que no ocurra).

- **Log-odds:** Es el logaritmo natural de las *odds*. Este paso permite que la relaci√≥n entre las variables y el resultado sea lineal, facilitando la estimaci√≥n con m√©todos de regresi√≥n.

::: callout-note
**Nota:** La escala de log-odds no tiene una interpretaci√≥n inmediata en porcentajes, pero al exponenciar los coeficientes ($e^{\beta\_j}$) recuperamos una medida interpretable: el **odds ratio**, que indica cu√°nto se multiplican las probabilidades relativas del evento cuando una variable cambia en una unidad.
:::

### Interpretaci√≥n de los coeficientes

Cada par√°metro $\beta\_j$ representa el **efecto parcial** de la variable $X_j$ sobre el logaritmo de las odds del evento, manteniendo las dem√°s constantes:

- Si $\beta_j > 0$: el aumento en$X_j$ incrementa la probabilidad de √©xito.  
- Si $\beta_j < 0$: el aumento en $X_j$ reduce la probabilidad de √©xito.  

Sin embargo, dado que los coeficientes se expresan en log-odds, solemos transformarlos a **odds ratios**:

$\text{odds ratio} = e^{\beta_j}$

Esta medida es m√°s intuitiva, ya que describe un cambio multiplicativo en las odds:

::: callout-tip
**Ejemplo interpretativo:** Si $e^{\beta_{\text{horas\_estudio}}} = 1.5$, entonces cada hora adicional de estudio aumenta en un **50 %** las probabilidades relativas de aprobar, manteniendo las dem√°s variables constantes.
:::

### Comportamiento no lineal del Logit

El modelo Logit captura **efectos decrecientes** a medida que la probabilidad se acerca a los extremos.  
Gr√°ficamente, su forma sigmoide muestra tres zonas:

| Zona | Probabilidad | Comportamiento |
|------|---------------|----------------|
| **Inferior (P‚âà0)** | Evento muy improbable | Cambios en X apenas afectan la probabilidad |
| **Central (P‚âà0.5)** | Regi√≥n de m√°xima sensibilidad | Peque√±os cambios en X producen grandes cambios en P |
| **Superior (P‚âà1)** | Evento casi seguro | Cambios en X tienen poco efecto adicional |

Esta propiedad hace del Logit una herramienta potente para **problemas de decisi√≥n**,  
donde la respuesta no cambia de forma constante, sino en umbrales o zonas cr√≠ticas.

üìò **En resumen:** El modelo Logit combina **rigor estad√≠stico** con **interpretabilidad econ√≥mica**, lo que lo convierte en una de las t√©cnicas m√°s utilizadas en Business Analytics. Permite traducir informaci√≥n observable en probabilidades, evaluar qu√© variables influyen en un resultado y apoyar decisiones basadas en datos y riesgo.

## Evaluaci√≥n del modelo

Evaluar un modelo de clasificaci√≥n no solo consiste en verificar cu√°ntas predicciones fueron correctas, sino en **entender c√≥mo y d√≥nde el modelo acierta o se equivoca**. Las m√©tricas permiten medir su desempe√±o bajo diferentes perspectivas: precisi√≥n, cobertura y capacidad de discriminaci√≥n entre clases. Las m√©tricas m√°s comunes incluyen:

| M√©trica | Descripci√≥n | Interpretaci√≥n pr√°ctica |
|----------|--------------|-------------------------|
| **Exactitud (Accuracy)** | Proporci√≥n de predicciones correctas sobre el total. | Mide el desempe√±o global del modelo, pero puede ser enga√±osa si las clases est√°n desbalanceadas. |
| **Sensibilidad (Recall o Tasa de Verdaderos Positivos)** | Capacidad del modelo para identificar correctamente los casos positivos. | Indica qu√© tan bien detecta el modelo a quienes realmente presentan el evento. |
| **Especificidad** | Capacidad del modelo para identificar correctamente los casos negativos. | Eval√∫a la habilidad para no confundir casos negativos con positivos. |
| **Precisi√≥n (Precision)** | Proporci√≥n de verdaderos positivos entre todos los positivos predichos. | Indica cu√°ntas de las predicciones positivas son realmente correctas. |
| **F1-Score** | Media arm√≥nica entre precisi√≥n y sensibilidad. | Balancea los errores tipo I y II; √∫til cuando las clases son desiguales. |
| **AUC-ROC** | √Årea bajo la curva ROC (Receiver Operating Characteristic). | Eval√∫a la capacidad general del modelo para distinguir entre clases. Cuanto m√°s cerca de 1, mejor. |

::: callout-note
**Matriz de confusi√≥n:**  Es la herramienta base para calcular todas las m√©tricas anteriores. Muestra los aciertos (predicciones correctas) y errores (predicciones incorrectas) del modelo:

|               | **Real Positivo (1)** | **Real Negativo (0)** |
|---------------|-----------------------|-----------------------|
| **Predicho Positivo (1)** | Verdaderos Positivos (VP) | Falsos Positivos (FP) |
| **Predicho Negativo (0)** | Falsos Negativos (FN) | Verdaderos Negativos (VN) |

Esta tabla permite diagnosticar el tipo de error predominante: si el modelo **no detecta casos verdaderos** (alta tasa de FN) o si **etiqueta err√≥neamente casos negativos como positivos** (alta tasa de FP).
:::

### Interpretaci√≥n estrat√©gica

Cada m√©trica tiene un significado **operativo** seg√∫n el contexto de negocio:

- En **riesgo crediticio**, un falso negativo (no identificar un cliente riesgoso) puede ser costoso.  
- En **salud**, un falso positivo (diagn√≥stico incorrecto de enfermedad) puede generar tratamientos innecesarios.  
- En **educaci√≥n**, un modelo que predice mal qui√©n est√° en riesgo de retirarse podr√≠a afectar la asignaci√≥n de tutor√≠as o becas.  
Por ello, **no existe una √∫nica m√©trica ‚Äúmejor‚Äù**; el an√°lisis debe centrarse en la m√©trica que maximiza el valor para la decisi√≥n.

::: callout-tip
**Resumen:** El modelo Logit es el punto de partida de la anal√≠tica predictiva moderna. Permite **clasificar observaciones**, **estimar probabilidades** y **analizar la influencia de cada variable**, combinando interpretabilidad estad√≠stica con valor pr√°ctico para la gesti√≥n y la estrategia empresarial.
:::

---

# Aplicaci√≥n en R

Para ilustrar el uso de los **modelos de clasificaci√≥n**, trabajaremos con una base sint√©tica que representa a **estudiantes inscritos en un curso universitario**. Cada registro contiene informaci√≥n sobre el comportamiento acad√©mico y el desempe√±o del estudiante a lo largo del semestre, lo que nos permitir√° **estimar la probabilidad de aprobar el curso** y analizar los factores que m√°s influyen en ese resultado.

En este contexto:

- Cada **observaci√≥n** corresponde a un estudiante.  
- La **variable dependiente** es binaria: `aprueba` (1 = aprueba, 0 = reprueba).  
- Las **variables explicativas** describen aspectos como el n√∫mero de horas de estudio, la asistencia, la participaci√≥n y la afinidad con la estad√≠stica.  

El objetivo es construir un **modelo Logit** que nos permita responder preguntas como:

- ¬øQu√© factores aumentan la probabilidad de aprobar el curso?  
- ¬øC√≥mo se interpreta el efecto de cada variable en t√©rminos de *odds ratio*?  
- ¬øQu√© tan bien puede el modelo predecir los resultados acad√©micos?  

Este tipo de an√°lisis es una herramienta clave en **Business Analytics**, ya que permite tomar decisiones basadas en datos ‚Äîpor ejemplo, identificar estudiantes en riesgo acad√©mico, dise√±ar estrategias de acompa√±amiento o evaluar la efectividad de las metodolog√≠as de ense√±anza.

::: callout-tip
üí° **C√≥mo usar este material:**  
Puedes ejecutar los _chunks_ de R directamente en el navegador gracias a **webR**, sin necesidad de instalar nada localmente.
:::

## Preparaci√≥n del entorno

El prop√≥sito de este bloque es asegurar un entorno **limpio, reproducible y funcional** antes de iniciar el an√°lisis.  
Primero, eliminamos cualquier objeto previo que pueda interferir con la sesi√≥n actual. Luego, instalamos (si es necesario) y cargamos los paquetes requeridos para la **manipulaci√≥n de datos**, la **visualizaci√≥n** y la **estimaci√≥n del modelo Logit**.  

Con esto, dejamos el entorno preparado para comenzar el an√°lisis aplicado.

```{webr-r}
## Limpiar el entorno de trabajo
rm(list = ls())

## Instalar paquetes (solo si es necesario)
install.packages("tidyverse")
install.packages("broom")
install.packages("pROC") 


## Cargar librer√≠as
library(tidyverse)  # Manipulaci√≥n y visualizaci√≥n de datos
library(broom)      # Para resumir resultados de modelos
library(pROC)       # Calcular la curva ROC y el AUC
 
## Fijar semilla para reproducibilidad
set.seed(123)
```

::: callout-note
Los paquetes `tidyverse` y `broom` son parte del ecosistema de an√°lisis de datos en R:
	‚Ä¢	`tidyverse` permite transformar y visualizar datos de manera eficiente.
	‚Ä¢	`broom` facilita la conversi√≥n de resultados de modelos estad√≠sticos en tablas ordenadas y listas para interpretar.
:::

## Ingesta de datos 

En esta secci√≥n realizamos la ingesta de datos, es decir, el proceso de generar o cargar la base que utilizaremos para estimar el modelo Logit. Cada registro representa a un estudiante, con variables relacionadas con su esfuerzo, participaci√≥n y rendimiento a lo largo del semestre.

La estructura de los datos es la siguiente:
	‚Ä¢	horas_estudio: promedio semanal de horas dedicadas al curso.
	‚Ä¢	asistencia: porcentaje de asistencia a clase.
	‚Ä¢	participacion: nivel de participaci√≥n en clase (0‚Äì100).
	‚Ä¢	uso_de_R: nivel de dominio de R (1‚Äì5).
	‚Ä¢	trabajos_entregados: cantidad de trabajos entregados (0‚Äì5).
	‚Ä¢	afinidad_estadistica: gusto por la estad√≠stica (0‚Äì100).
	‚Ä¢	aprueba: resultado final (1 = aprueba, 0 = reprueba).
	‚Ä¢	retira: indica si el estudiante se retir√≥ del curso antes de finalizar (1 = s√≠, 0 = no).

Nuestro objetivo ser√° estimar c√≥mo cada una de estas variables influye en la probabilidad de aprobar el curso.

```{webr-r}
#| warning: false
#| message: false

## generar los datos
source("https://raw.githubusercontent.com/ba-in-r/01-slides/main/week-13/data/week-13.r")

## chuequear objeto
head(datos)
```

## Estimaci√≥n del Modelo Logit

Ahora s√≠, pasemos a la parte pr√°ctica: vamos a **estimar un modelo Logit** que nos ayude a predecir la probabilidad de que un estudiante **apruebe el curso**. La idea es bastante simple: queremos entender qu√© factores ‚Äîcomo las horas de estudio, la asistencia, la participaci√≥n en clase o el gusto por la estad√≠stica‚Äî est√°n realmente asociados con aprobar o no. Podr√≠amos pensar en esto como tratar de responder preguntas del tipo:

‚Äú¬øQu√© tanto influye estudiar m√°s o asistir con regularidad en la probabilidad de aprobar?‚Äù  
‚Äú¬øTiene impacto que el estudiante use m√°s R o entregue m√°s trabajos?‚Äù

El modelo Logit nos permite cuantificar esas relaciones de forma probabil√≠stica.

### ¬øC√≥mo se formula el modelo?

En pocas palabras, el Logit relaciona las variables explicativas con la **probabilidad de aprobar** a trav√©s de una funci√≥n no lineal llamada *funci√≥n log√≠stica*. Matem√°ticamente, el modelo se puede escribir as√≠:

$\log\left(\frac{P(\text{aprueba}=1)}{1 - P(\text{aprueba}=1)}\right) =$
$\beta_0 + \beta_1(\text{horas\_estudio}) + ... + \beta_6(\text{afinidad\_estadistica})$

D√≥nde las variables explicativas son: $\text{horas\_estudio}$ + $\text{asistencia}$ + $\text{participacion}$ + $\text{uso\_de\_R}$ + $\text{trabajos\_entregados}$ + $\text{afinidad\_estadistica}$. Lo que hace este modelo es algo muy interesante: en lugar de predecir directamente una probabilidad (que siempre debe estar entre 0 y 1), predice el **logaritmo de las odds** o razones de probabilidad. Esto permite usar una relaci√≥n lineal en el ‚Äúfondo‚Äù del modelo, pero que al transformarse con la funci√≥n log√≠stica se mantiene siempre dentro del rango v√°lido.

### ¬øQu√© significa cada parte?

El t√©rmino del lado izquierdo,  $\log\left(\frac{P(Y=1)}{1 - P(Y=1)}\right)$ es el **logaritmo de las odds**, es decir, c√≥mo cambian las probabilidades relativas de aprobar frente a reprobar.

Los coeficientes $\beta_j$) nos dicen **cu√°nto cambia esa raz√≥n** cuando una variable cambia en una unidad, manteniendo las dem√°s constantes.  Por ejemplo, si el coeficiente de `horas_estudio` es positivo, significa que estudiar m√°s est√° asociado con una mayor probabilidad de aprobar.

En resumen, el modelo nos permite *traducir datos en probabilidades*. A partir de los valores observados de las variables, podemos estimar qu√© tan probable es que un estudiante apruebe, y adem√°s entender **qu√© factores son los que realmente mueven la aguja**.

### Estimaci√≥n en R

Usaremos la funci√≥n `glm()` (Generalized Linear Model) especificando `family = binomial(link = "logit")` para estimar el modelo log√≠stico.  Esta funci√≥n ajusta un modelo de regresi√≥n que predice la probabilidad de que un estudiante **apruebe el curso**, dada su combinaci√≥n de caracter√≠sticas.

```{webr-r}
# Estimar el modelo logit
modelo_logit <- glm(aprueba ~ horas_estudio + asistencia + participacion + 
                      uso_de_R + trabajos_entregados + afinidad_estadistica,
                    data = datos,
                    family = binomial(link = "logit"))

# Resumen general
summary(modelo_logit)
```

::: callout-note
**Interpretaci√≥n inicial:** Un coeficiente positivo indica que un aumento en la variable incrementa la probabilidad de aprobar, mientras que un coeficiente negativo la reduce. Sin embargo, los valores de los coeficientes est√°n en escala log-odds, por lo que deben transformarse para interpretarse como odds ratios.
:::

### Interpretaci√≥n de coeficientes

Para obtener una interpretaci√≥n m√°s intuitiva, transformamos los coeficientes mediante la exponenciaci√≥n:

$\text{odds ratio} = e^{\beta_j}$

Un odds ratio mayor a 1 indica que un aumento en la variable incrementa la probabilidad de aprobar, mientras que un valor menor a 1 indica que la reduce.

```{webr-r}
# 1. Extraemos los resultados del modelo en formato ordenado usando broom::tidy()
r_logit_1 <- tidy(modelo_logit)
head(r_logit_1)
```

```{webr-r}
# 2. Creamos una nueva columna 'odds_ratio' aplicando la funci√≥n exponencial a los coeficientes
#    Esto convierte los coeficientes en t√©rminos de cambio multiplicativo en las odds
r_logit_2 <- mutate(r_logit_1, odds_ratio = exp(estimate))
head(r_logit_2)
```

```{webr-r}
# 3. Seleccionamos √∫nicamente las columnas de inter√©s:
#    - term: nombre de la variable
#    - estimate: coeficiente estimado (log-odds)
#    - odds_ratio: raz√≥n de probabilidades
#    - p.value: nivel de significancia estad√≠stica
r_logit_3 <- select(r_logit_2, term, estimate, odds_ratio, p.value)

# 4. Mostramos la tabla final con resultados listos para interpretaci√≥n
r_logit_3
```

::: callout-tip
**Ejemplo de interpretaci√≥n:** Si el odds ratio de horas_estudio es 1.27, significa que por cada hora adicional de estudio, las probabilidades de aprobar el curso se incrementan en un 27%, manteniendo las dem√°s variables constantes.
:::

## Evaluaci√≥n del Modelo Logit

Una vez estimado el modelo Logit, necesitamos **evaluar su capacidad predictiva**:¬øqu√© tan bien logra distinguir entre los estudiantes que aprueban y los que no? 

En esta secci√≥n construiremos una **matriz de confusi√≥n**, calcularemos **m√©tricas de desempe√±o** y visualizaremos la **curva ROC** (*Receiver Operating Characteristic*) para medir el poder discriminatorio del modelo.

### Predicciones del modelo

Usamos la funci√≥n `predict()` para calcular la **probabilidad estimada de aprobar** (`prob_predicha`) y clasificamos a cada estudiante seg√∫n un umbral de 0.5 (es decir, si la probabilidad es mayor a 0.5, se predice que aprueba).

```{webr-r}
# Generar predicciones
datos <- mutate(datos,
                prob_predicha = predict(modelo_logit, type = "response"),
                aprueba_pred = if_else(prob_predicha > 0.5, 1, 0))

# Verificar las primeras observaciones
head(select(datos, aprueba, prob_predicha, aprueba_pred))
```

::: callout-note
**Nota:** El valor 0.5 es un umbral arbitrario.
Podemos ajustarlo seg√∫n los objetivos del an√°lisis:
	‚Ä¢	Usar un umbral menor (p. ej. 0.4) si queremos detectar m√°s estudiantes en riesgo (aunque aumenten los falsos positivos).
	‚Ä¢	Usar un umbral mayor (p. ej. 0.6) si preferimos mayor precisi√≥n en las predicciones positivas.
:::

### Matriz de confusi√≥n

Una vez que el modelo ha hecho sus predicciones, el siguiente paso es **evaluar qu√© tan bien lo hizo**. Para eso usamos una herramienta cl√°sica en clasificaci√≥n: la **matriz de confusi√≥n**. Esta matriz no es m√°s que una tabla de doble entrada que compara, para cada observaci√≥n, lo que el modelo **predijo** frente a lo que **realmente ocurri√≥**. Es decir, muestra los aciertos y errores del modelo de una forma muy clara.

```{webr-r}
# Matriz de confusi√≥n
table(Prediccion = datos$aprueba_pred, Real = datos$aprueba)
```

Esta matriz no es m√°s que una tabla de doble entrada que compara, para cada observaci√≥n, lo que el modelo **predijo** frente a lo que **realmente ocurri√≥**. Es decir, muestra los aciertos y errores del modelo de una forma muy clara. Cuando ejecutes el comando para crear la matriz, obtendr√°s una tabla similar a:

|             | Real = 0 | Real = 1 |
|--------------|-----------|-----------|
| **Predicho = 0** |  176  |  122   |
| **Predicho = 1** |  418   |  1284  |

Cada celda te est√° contando **cu√°ntos estudiantes** cayeron en cada situaci√≥n posible. Veamos qu√© significa cada una:

- **Verdaderos positivos (VP):** el modelo predijo que el estudiante aprobar√≠a, y efectivamente aprob√≥.  
- **Verdaderos negativos (VN):** el modelo predijo que el estudiante reprobar√≠a, y as√≠ fue.  
- **Falsos positivos (FP):** el modelo predijo que aprobar√≠a, pero en realidad reprob√≥.  
- **Falsos negativos (FN):** el modelo predijo que reprobar√≠a, pero el estudiante aprob√≥.

#### ¬øPor qu√© se llama ‚Äúconfusi√≥n‚Äù?

Porque literalmente nos muestra **en qu√© se confunde el modelo** üòÖ.  
Idealmente quisi√©ramos una matriz donde solo existan VP y VN (es decir, el modelo no se equivoca nunca).  
Pero en la pr√°ctica eso rara vez ocurre: siempre hay un equilibrio entre los errores de tipo **FP** y **FN**,  
y depende del contexto cu√°l de ellos es m√°s costoso.

**Ejemplo aplicado:**

- En un curso, un **falso negativo** (el modelo predice que el estudiante no aprobar√°, pero s√≠ lo hace) puede no ser tan grave, porque el estudiante tuvo un buen resultado.  
- En cambio, un **falso positivo** (el modelo predice que aprobar√°, pero no lo hace) podr√≠a significar que el sistema subestim√≥ el riesgo acad√©mico y el estudiante no recibi√≥ la ayuda que necesitaba.

Por eso, **interpretar la matriz de confusi√≥n va m√°s all√° de contar aciertos**: nos ayuda a entender **qu√© tipo de error comete el modelo** y **qu√© tan grave puede ser** en el contexto real.

### M√©tricas de desempe√±o

A partir de esta matriz, podemos calcular todas las m√©tricas de desempe√±o del modelo: la **exactitud (accuracy)**, la **sensibilidad (recall)**, la **especificidad** y la **precisi√≥n (precision)**. Cada una de ellas utiliza una combinaci√≥n de estos cuatro valores (VP, VN, FP, FN) para describir un aspecto distinto del rendimiento del modelo.

$\text{Accuracy} = \frac{VP + VN}{VP + VN + FP + FN}$

$\text{Sensibilidad (Recall)} = \frac{VP}{VP + FN}$

$\text{Especificidad} = \frac{VN}{VN + FP}$

$\text{Precisi√≥n (Precision)} = \frac{VP}{VP + FP}$

```{webr-r}
## Calcular m√©tricas de desempe√±o
VP <- sum(datos$aprueba_pred == 1 & datos$aprueba == 1)
VN <- sum(datos$aprueba_pred == 0 & datos$aprueba == 0)
FP <- sum(datos$aprueba_pred == 1 & datos$aprueba == 0)
FN <- sum(datos$aprueba_pred == 0 & datos$aprueba == 1)

## Metricas
accuracy <- (VP + VN) / (VP + VN + FP + FN)
sensibilidad <- VP / (VP + FN)
especificidad <- VN / (VN + FP)
precision <- VP / (VP + FP)

## Metricas del modelo
tibble(accuracy = round(accuracy, 3),
sensibilidad = round(sensibilidad, 3),
especificidad = round(especificidad, 3),
precision = round(precision, 3))
```

::: callout-tip
üí° Interpretaci√≥n pr√°ctica:
	‚Ä¢	Exactitud (Accuracy): proporci√≥n de predicciones correctas.
	‚Ä¢	Sensibilidad: qu√© tan bien el modelo identifica a quienes aprueban.
	‚Ä¢	Especificidad: qu√© tan bien identifica a quienes reprueban.
	‚Ä¢	Precisi√≥n: de los que el modelo predice como aprobados, cu√°ntos realmente aprueban.
:::


### Curva ROC y AUC

Hasta este punto ya sabemos cu√°ntas predicciones acierta o se equivoca nuestro modelo. Pero todav√≠a no hemos respondido algo importante: **¬øQu√© tan bien distingue el modelo entre quienes aprueban y quienes no?**

Ah√≠ es donde entra en juego la **curva ROC**, una de las herramientas m√°s potentes y visuales para evaluar modelos de clasificaci√≥n. 

#### ¬øQu√© representa la curva ROC?

La curva ROC (Receiver Operating Characteristic) muestra la relaci√≥n entre dos tasas calculadas a partir de la matriz de confusi√≥n:

- **Eje Y:** la tasa de verdaderos positivos (Sensibilidad o Recall) ‚Üí qu√© tan bien el modelo detecta correctamente los casos positivos.  
- **Eje X:** la tasa de falsos positivos (1 - Especificidad) ‚Üí cu√°ntos negativos fueron clasificados err√≥neamente como positivos.

Cada punto de la curva representa un umbral de decisi√≥n distinto. Por ejemplo:
- Si el umbral es **0.5**, el modelo predice ‚Äúaprueba‚Äù cuando la probabilidad es mayor a 0.5.  
- Si bajamos el umbral a **0.3**, el modelo ser√° m√°s ‚Äúgeneroso‚Äù y clasificar√° m√°s estudiantes como aprobados (mayor sensibilidad, pero m√°s falsos positivos).  
- Si lo subimos a **0.7**, el modelo ser√° m√°s estricto (menos falsos positivos, pero tambi√©n m√°s falsos negativos).

Por eso, la curva ROC **resume el comportamiento del modelo a trav√©s de todos los posibles umbrales**.

#### El √Årea Bajo la Curva (AUC)

El **√Årea Bajo la Curva (AUC)** es una medida global de desempe√±o que resume la capacidad del modelo para separar las dos clases. Su valor oscila entre 0 y 1:

| Valor de AUC | Interpretaci√≥n | Descripci√≥n |
|---------------|----------------|--------------|
| **0.5** | Sin poder discriminatorio | El modelo predice al azar (como lanzar una moneda). |
| **0.6 ‚Äì 0.7** | Discriminaci√≥n pobre | El modelo distingue las clases, pero con bajo rendimiento. |
| **0.7 ‚Äì 0.9** | Buen modelo | El modelo separa adecuadamente las clases. |
| **> 0.9** | Excelente modelo | El modelo casi clasifica perfectamente. |
| **1.0** | Clasificaci√≥n perfecta | Ideal (pero rara vez alcanzable en la pr√°ctica). |

üí° En pocas palabras: Cuanto mayor sea el AUC, **mejor capacidad tiene el modelo para diferenciar entre aprobados y no aprobados**, sin importar qu√© umbral usemos.

#### ¬øC√≥mo se interpreta visualmente?

- Una **curva ROC ‚Äúm√°s arriba y m√°s a la izquierda‚Äù** indica un mejor modelo: logra una alta sensibilidad con pocos falsos positivos.  
- Una **curva cercana a la diagonal (AUC ‚âà 0.5)** indica un modelo que no tiene valor predictivo.  
- Una **curva casi perfecta** se pega a los bordes del gr√°fico (AUC cercano a 1), lo cual indica una excelente separaci√≥n entre clases.

En el caso del modelo Logit, la curva suele ser suave y continua, ya que trabaja con probabilidades estimadas de manera gradual.

```{webr-r}
# Calcular la curva ROC y el AUC
roc_obj <- roc(datos$aprueba, datos$prob_predicha)

# Mostrar AUC
auc(roc_obj)

# Graficar la curva ROC
plot(roc_obj, col = "blue", lwd = 2, main = "Curva ROC ‚Äî Modelo Logit")
abline(a = 0, b = 1, lty = 2, col = "gray")
```

::: callout-note
Un valor de AUC entre 0.7 y 0.9 indica un buen poder discriminatorio, mientras que valores superiores a 0.9 suelen considerarse excelentes. Si el AUC est√° cerca de 0.5, el modelo no est√° capturando patrones √∫tiles.
:::

### Visualizaci√≥n de resultados

Finalmente, podemos representar la relaci√≥n entre la probabilidad predicha de aprobar y alguna variable explicativa, como las horas de estudio.

```{webr-r}
ggplot(data=datos , aes(x=horas_estudio , y=prob_predicha)) +
geom_point(alpha = 0.4, color = "steelblue") +
geom_smooth(method = "loess", se = FALSE, color = "black") +
labs(title = "Probabilidad predicha de aprobar seg√∫n horas de estudio",
     x = "Horas de estudio por semana",
     y = "Probabilidad estimada de aprobar") +
theme_minimal()
```
  
::: callout-tip
**Interpretaci√≥n visual:**
La curva creciente refleja la naturaleza no lineal del modelo Logit. A medida que aumentan las horas de estudio, la probabilidad de aprobar se incrementa, pero a un ritmo decreciente: los beneficios marginales de estudiar m√°s disminuyen.
:::

# Actividad en Clase

## Instrucciones:

1. Ejecute los *chunks* de c√≥digo proporcionados en R (puede hacerlo directamente en el navegador o en RStudio).  
2. Observe los resultados obtenidos en cada secci√≥n.  
3. Genere un documento en **Word (.docx)** donde:  
   - Copie las preguntas que aparecen al final.  
   - Redacte sus interpretaciones y conclusiones con base en los resultados.  
   - **No copie el c√≥digo**, solo las tablas y redacte sus respuestas.  
4. Suba su documento a la plataforma **Intu**, en la actividad correspondiente a la **Semana 13 ‚Äî Modelo Logit (Predicci√≥n de Retiro)**.

### Estimaci√≥n del modelo Logit

Ejecute el siguiente c√≥digo para estimar un modelo Logit que prediga la **probabilidad de que un estudiante se retire del curso**, usando las variables explicativas relacionadas con esfuerzo y participaci√≥n.  
‚ö†Ô∏è No incluya la variable `aprueba` en el modelo.

```{webr-r}
# Estimar el modelo logit
modelo_logit <- glm(retira ~ horas_estudio + asistencia + participacion + 
                    uso_de_R + trabajos_entregados + afinidad_estadistica,
                    data = datos,
                    family = binomial(link = "logit"))

# Resumen general
summary(modelo_logit)
```

## Evaluaci√≥n del Modelo Logit

Una vez que hayas estimado tu modelo Logit, el siguiente paso es **evaluar qu√© tan bien funciona**. En esta parte debes comprobar la capacidad predictiva del modelo, es decir, qu√© tan bien distingue entre los estudiantes que **se retiran** y los que **no se retiran** del curso. Para esta evaluaci√≥n debes **usar exactamente el mismo c√≥digo que vimos en clase**, adapt√°ndolo al modelo que acabas de estimar (`modelo_logit`). No necesitas escribir nuevas funciones ni cambiar el procedimiento. Simplemente ejecuta paso a paso los bloques de c√≥digo que ya exploramos para:

1. **Generar las predicciones** del modelo (`predict()`):  
   - Calcula la probabilidad estimada de retiro (`prob_predicha`).  
   - Clasifica a cada estudiante como retirado (`1`) o no retirado (`0`) seg√∫n un umbral de 0.5.

2. **Construir la matriz de confusi√≥n:**  
   - Compara las predicciones con los valores reales de `retira`.  
   - Identifica los verdaderos positivos (VP), falsos positivos (FP), verdaderos negativos (VN) y falsos negativos (FN).

3. **Calcular las m√©tricas de desempe√±o:**  
   - Usa el mismo conjunto de operaciones visto en clase para obtener:
     - **Exactitud (Accuracy)** ‚Üí proporci√≥n de predicciones correctas.  
     - **Sensibilidad (Recall)** ‚Üí qu√© tan bien detecta a quienes se retiran.  
     - **Especificidad** ‚Üí qu√© tan bien detecta a quienes permanecen.  
     - **Precisi√≥n (Precision)** ‚Üí cu√°ntas predicciones de retiro fueron correctas.  

4. **Analizar la curva ROC y el AUC:**  
   - Calcula el √Årea Bajo la Curva (AUC) usando `roc()` y `auc()` del paquete `pROC`.  

## Preguntas para el informe

1. Interpretaci√≥n general
	‚Ä¢	¬øQu√© variables parecen tener mayor influencia en la probabilidad de retiro seg√∫n el resumen del modelo (summary(modelo_logit))?
	‚Ä¢	¬øCu√°l es el signo del coeficiente asociado a horas_estudio y c√≥mo lo interpretar√≠as?

2. Evaluaci√≥n del desempe√±o
	‚Ä¢	¬øQu√© tan bien clasifica el modelo seg√∫n las m√©tricas de desempe√±o calculadas?
	‚Ä¢	Si la exactitud (accuracy) es del 75 %, ¬øc√≥mo interpretar√≠as este resultado en este contexto?
	‚Ä¢	¬øEl modelo tiende a cometer m√°s falsos positivos o falsos negativos? ¬øQu√© implicaciones tendr√≠a eso?

3. Curva ROC y visualizaci√≥n
	‚Ä¢	¬øQu√© valor obtuvo el AUC y qu√© indica sobre el poder predictivo del modelo?
	‚Ä¢	¬øC√≥mo se interpreta la relaci√≥n entre las horas de estudio y la probabilidad de retiro en el gr√°fico final?

::: callout-tip
üí° Entrega: Suba su documento con las respuestas a la plataforma Intu, en la actividad correspondiente a la Semana 13 ‚Äî Modelo Logit. Y suba el script con el que realizo el proedimiento. Recuerde que se evaluar√° la claridad de sus interpretaciones, la consistencia con los resultados del modelo y su capacidad para proponer acciones basadas en los hallazgos.
:::






